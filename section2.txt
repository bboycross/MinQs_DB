5
HDFS
Hadoop 분산파일시스템
큰 파일을 처리하기 위해,
매우 큰 파일, 빅데이터를 처리할수 있도록 전체클러스터에서 분산처리할수있고, 대용량파일을 블록으로 분할하면 단일시스템의 드라이브 제한
HDFS 아키텍쳐
네임노드 : 데이터노드 블럭 추적, 기록 로그

특정시간에 하나의 네임노드만 활성화 되야함.
그렇지않으면 클라이언트가 거절할 수 있음
문제해결방법
1. 메타데이터를 지속적으로 로컬디스크나 NFS에 백업하면 복원 가능
2. 보조네임노드는 실제 네임노드가 아니고, 카피해둬야함.
3. HDFS Federation
각각의 네임노드의 볼륨을 관리
4. HDFS 고가용성 보호
항상 모든 클라이언트가 주어진 시간에 동일한 네임노드를 사용

HDFS 사용
UI(Ambari)
Command_Line Interface
HTTP / HDFS Proxies
Java interface
NFS Gateway


6
http://127.0.0.1:8888/ : 기본페이지 연결
http://127.0.0.1:8080/ : Ambari 바로이동
HDFS 탭
가상데이터노드에서 네임노드를 실행하고 있음

hadoop fs(명령 목록 보기)
hadoop fs -ls (하둡에 있는 목록 보기)
hadoop fs -mkdir dd ( 하둡 dd폴더생성)
hadoop fs -copyFromLocal data.data dd/data.data (하둡 dd폴더에 data.data 파일 올리기)
hadoop fs -rm dd/data.data (data.data 파일삭제)
hadoop fs -rmdir dd (dd 폴더삭제)

7
퍼티를 사용해 파일설치

8
MapReduce 이해
모든 데이터를 파티션으로 나눠서 파티션간 병렬로 처리할수 있음
클러스터가 어떻게 완료되었는지, 실패가 처리되는 방식 관리
데이터맵핑, 데이터축소
Input Data -> Mapper -> K1:V K2:V K3:V K1:V K1:V (동일한 키를 가진 경우도 있음)

MapReduce Sort, Shuffle
키값정렬, 같은키에대해 밸류값 섞기 

data -> Mapper(K:V) -> Shuffle+Sort(K:V,K:V,V) -> Reducer


9
24_happening.jpg 확인
MapReduce = Java 언어로 작성
Streaming = Python, 표준입력데이터 -> K:V -> 표준출력데이터


10
예제 등급점수로 무비등급나누기 이론
Python 사용자함수를 이용하여 MapReduce 하기

11
예제 등급점수로 무비등급나누기 실습 파일 다운
Python, MRjob, nano 설치

12
예제 등급점수로 무비등급나누기 실습 MapReduce 실행

13
예제 등급점수로 무비등급나누기 실습 인기순위 정렬


14
평점 k / 무비id v
nano - 파이선 코드 수정 




